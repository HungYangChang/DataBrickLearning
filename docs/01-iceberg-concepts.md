# Understanding Apache Iceberg

> **Reading Time:** 20-30 minutes  
> **Prerequisites:** Basic SQL knowledge, familiarity with data warehousing concepts

---

## What is Apache Iceberg?

Apache Iceberg is an **open table format** designed for huge analytic datasets. Think of it as a smart layer that sits between:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMPUTE ENGINES                             â”‚
â”‚    Spark  â€¢  Trino  â€¢  Flink  â€¢  Snowflake  â€¢  Athena   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–²
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              APACHE ICEBERG                              â”‚
â”‚         (Table Format + Metadata Layer)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–²
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CLOUD STORAGE                               â”‚
â”‚         S3  â€¢  ADLS  â€¢  GCS  â€¢  HDFS                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Why Was Iceberg Created?

Traditional data lakes have serious problems:

| Problem | Traditional Data Lake | With Iceberg |
|---------|----------------------|--------------|
| **Transactions** | No ACID guarantees | Full ACID support |
| **Schema Changes** | Requires data rewrite | No rewrite needed |
| **Time Travel** | Not possible | Query any past state |
| **Partition Changes** | Painful, requires rewrite | Seamless evolution |
| **Concurrent Writes** | Conflicts & corruption | Safe concurrent access |
| **Query Planning** | Scan all files | Smart file skipping |

---

## The Metadata Architecture

> â­ **This is the most important concept to understand.**

An Iceberg table is NOT just a pile of Parquet files. It has a hierarchical metadata structure that enables all its powerful features.

### The Hierarchy (Top to Bottom)

```
LEVEL 1: CATALOG
    â”‚
    â”‚   "Where is table X?"
    â”‚   Maps table names â†’ metadata file locations
    â”‚
    â–¼
LEVEL 2: METADATA FILE (JSON)
    â”‚
    â”‚   "What does this table look like?"
    â”‚   â€¢ Schema definition
    â”‚   â€¢ Partition specification  
    â”‚   â€¢ Current snapshot pointer
    â”‚   â€¢ Table properties
    â”‚
    â–¼
LEVEL 3: SNAPSHOT
    â”‚
    â”‚   "What was the table state at this moment?"
    â”‚   â€¢ Unique snapshot ID
    â”‚   â€¢ Timestamp
    â”‚   â€¢ Operation type (append, overwrite, delete)
    â”‚   â€¢ Pointer to manifest list
    â”‚
    â–¼
LEVEL 4: MANIFEST LIST (Avro file)
    â”‚
    â”‚   "Which manifest files make up this snapshot?"
    â”‚   â€¢ List of manifest file paths
    â”‚   â€¢ Partition summaries for quick pruning
    â”‚   â€¢ File counts
    â”‚
    â–¼
LEVEL 5: MANIFEST FILES (Avro files)
    â”‚
    â”‚   "Which data files contain my data?"
    â”‚   â€¢ Data file paths
    â”‚   â€¢ Partition values
    â”‚   â€¢ Column statistics (min, max, null count)
    â”‚   â€¢ Record counts
    â”‚
    â–¼
LEVEL 6: DATA FILES (Parquet, ORC, or Avro)

    The actual data rows
```

### Visual Example

```
my_catalog.my_database.products
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  metadata/v3.metadata.json                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ "current-snapshot-id": 789                          â”‚  â”‚
â”‚  â”‚ "schemas": [...]                                    â”‚  â”‚
â”‚  â”‚ "partition-specs": [...]                            â”‚  â”‚
â”‚  â”‚ "snapshots": [                                      â”‚  â”‚
â”‚  â”‚   { "snapshot-id": 789, "manifest-list": "snap-789"}â”‚  â”‚
â”‚  â”‚   { "snapshot-id": 456, "manifest-list": "snap-456"}â”‚  â”‚
â”‚  â”‚ ]                                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼ (current snapshot)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  snap-789-manifest-list.avro                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ manifest-1.avro â†’ partition=Electronics, 50 files  â”‚  â”‚
â”‚  â”‚ manifest-2.avro â†’ partition=Clothing, 30 files     â”‚  â”‚
â”‚  â”‚ manifest-3.avro â†’ partition=Home, 25 files         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  manifest-1.avro                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ data/part-00001.parquet                             â”‚  â”‚
â”‚  â”‚   â†’ partition: Electronics                          â”‚  â”‚
â”‚  â”‚   â†’ records: 10,000                                 â”‚  â”‚
â”‚  â”‚   â†’ price_min: 9.99, price_max: 999.99             â”‚  â”‚
â”‚  â”‚                                                     â”‚  â”‚
â”‚  â”‚ data/part-00002.parquet                             â”‚  â”‚
â”‚  â”‚   â†’ partition: Electronics                          â”‚  â”‚
â”‚  â”‚   â†’ records: 8,500                                  â”‚  â”‚
â”‚  â”‚   â†’ price_min: 14.99, price_max: 1299.99           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data/part-00001.parquet                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ id=1, name="Laptop", category="Electronics"...     â”‚  â”‚
â”‚  â”‚ id=2, name="Phone", category="Electronics"...      â”‚  â”‚
â”‚  â”‚ ...                                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This Structure Matters

| Benefit | How Metadata Enables It |
|---------|------------------------|
| **Atomic commits** | New snapshot only visible after metadata file update completes |
| **Time travel** | Old snapshots retained, each points to its own manifest list |
| **Fast query planning** | Column stats in manifests enable file skipping without reading data |
| **Partition pruning** | Partition info in manifests lets engine skip irrelevant files |
| **Concurrent safety** | Optimistic concurrency on metadata file updates |

---

## Snapshots and Time Travel

### What is a Snapshot?

Every write operation creates a new **snapshot**â€”an immutable point-in-time view of your table.

```
Timeline:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â–¶

   Snapshot 1        Snapshot 2        Snapshot 3        Snapshot 4
   (Initial)         (+50 rows)        (-10 rows)        (+column)
       â”‚                 â”‚                 â”‚                 â”‚
   Jan 1st           Jan 2nd           Jan 3rd           Jan 4th
       â”‚                 â”‚                 â”‚                 â”‚
       â–¼                 â–¼                 â–¼                 â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 1000  â”‚         â”‚ 1050  â”‚         â”‚ 1040  â”‚         â”‚ 1040  â”‚
   â”‚ rows  â”‚         â”‚ rows  â”‚         â”‚ rows  â”‚         â”‚ rows  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Operations That Create Snapshots

| Operation | What Happens |
|-----------|--------------|
| `INSERT INTO` | Adds new data files, creates snapshot |
| `UPDATE` | Rewrites affected files, creates snapshot |
| `DELETE` | Marks rows deleted or rewrites files, creates snapshot |
| `MERGE INTO` | Combination of insert/update/delete, creates snapshot |
| `OPTIMIZE` / Compaction | Rewrites small files into larger ones, creates snapshot |

### Time Travel Queries

```sql
-- Query the current state
SELECT * FROM products;

-- Query as of a specific timestamp
SELECT * FROM products 
TIMESTAMP AS OF '2024-01-15 10:00:00';

-- Query as of a specific snapshot ID
SELECT * FROM products 
VERSION AS OF 1234567890;

-- Compare two points in time
SELECT 
    'before' as state, COUNT(*) 
FROM products VERSION AS OF 100
UNION ALL
SELECT 
    'after' as state, COUNT(*) 
FROM products VERSION AS OF 200;
```

### Snapshot Retention

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SNAPSHOT LIFECYCLE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Active â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Expired â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Deleted           â”‚
â”‚                                                             â”‚
â”‚   â€¢ Queryable         â€¢ Not queryable     â€¢ Gone forever   â”‚
â”‚   â€¢ Takes storage     â€¢ Files orphaned    â€¢ Storage freed  â”‚
â”‚   â€¢ Time travel OK    â€¢ Awaiting cleanup                   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Default retention: varies by implementation (often 5-7 days)
```

**Key Tradeoff:**
- Longer retention = More time travel capability, but higher storage cost
- Shorter retention = Lower storage cost, but limited historical access

---

## Hidden Partitioning

### The Problem with Traditional Partitioning

In Hive-style partitioning, you must:
1. Know the exact partition columns
2. Write queries with explicit partition filters
3. Rewrite ALL data if you want to change partitioning

```sql
-- Hive style: You MUST know the partition structure
SELECT * FROM products 
WHERE year = 2024 AND month = 1 AND day = 15;

-- Without partition filter: FULL TABLE SCAN! ğŸ˜±
SELECT * FROM products 
WHERE order_date = '2024-01-15';
```

### Iceberg's Solution: Partition Transforms

Iceberg stores partition information in metadata. You write normal queries, and Iceberg automatically prunes partitions.

```sql
-- Iceberg: Just write normal predicates
SELECT * FROM products 
WHERE order_date = '2024-01-15';

-- Iceberg reads metadata, sees partition transform is day(order_date),
-- and automatically prunes to only the relevant partition!
```

### Available Partition Transforms

| Transform | Input | Output | Use Case |
|-----------|-------|--------|----------|
| `identity(col)` | value | same value | Low-cardinality columns |
| `year(ts)` | 2024-03-15 | 2024 | Yearly analysis |
| `month(ts)` | 2024-03-15 | 2024-03 | Monthly analysis |
| `day(ts)` | 2024-03-15 | 2024-03-15 | Daily analysis |
| `hour(ts)` | 2024-03-15 14:30 | 2024-03-15-14 | Hourly analysis |
| `bucket(N, col)` | any value | 0 to N-1 | Distribute evenly |
| `truncate(L, col)` | "Electronics" | "Elec" (if L=4) | String grouping |

### Visual Example

```
Table Definition:
  PARTITIONED BY (month(order_date), bucket(16, customer_id))

Data Layout on Storage:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ s3://bucket/warehouse/orders/                                â”‚
â”‚                                                             â”‚
â”‚ â”œâ”€â”€ order_date_month=2024-01/                               â”‚
â”‚ â”‚   â”œâ”€â”€ customer_id_bucket=0/                               â”‚
â”‚ â”‚   â”‚   â””â”€â”€ part-00001.parquet                              â”‚
â”‚ â”‚   â”œâ”€â”€ customer_id_bucket=1/                               â”‚
â”‚ â”‚   â”‚   â””â”€â”€ part-00002.parquet                              â”‚
â”‚ â”‚   â””â”€â”€ ...                                                 â”‚
â”‚ â”‚                                                           â”‚
â”‚ â”œâ”€â”€ order_date_month=2024-02/                               â”‚
â”‚ â”‚   â”œâ”€â”€ customer_id_bucket=0/                               â”‚
â”‚ â”‚   â””â”€â”€ ...                                                 â”‚
â”‚ â””â”€â”€ ...                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query: WHERE order_date = '2024-01-15' AND customer_id = 12345
  â†’ Iceberg computes: month = 2024-01, bucket = 7
  â†’ Only reads files in: order_date_month=2024-01/customer_id_bucket=7/
```

---

## Schema Evolution

### The Problem with Traditional Formats

Changing schema in traditional formats often means:
- Rewriting the entire table
- Downtime during migration
- Complex ETL to handle old vs new data

### How Iceberg Handles Schema Changes

Iceberg tracks columns by **unique numeric IDs**, not by name or position.

```
Original Schema:                    After Evolution:
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID â”‚ Name       â”‚ Type     â”‚     â”‚ ID â”‚ Name             â”‚ Type     â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1  â”‚ product_id â”‚ long     â”‚     â”‚ 1  â”‚ product_id       â”‚ long     â”‚
â”‚ 2  â”‚ name       â”‚ string   â”‚     â”‚ 2  â”‚ product_name     â”‚ string   â”‚ â† Renamed
â”‚ 3  â”‚ price      â”‚ decimal  â”‚     â”‚ 3  â”‚ price            â”‚ decimal  â”‚
â”‚ 4  â”‚ category   â”‚ string   â”‚     â”‚ 5  â”‚ rating           â”‚ double   â”‚ â† Added
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ -- â”‚ (category)       â”‚ dropped  â”‚ â† Dropped
                                   â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Supported Schema Changes (No Data Rewrite!)

| Change | Command | Notes |
|--------|---------|-------|
| **Add column** | `ALTER TABLE t ADD COLUMN col TYPE` | Old files return NULL for new column |
| **Drop column** | `ALTER TABLE t DROP COLUMN col` | Data remains, just hidden from queries |
| **Rename column** | `ALTER TABLE t RENAME COLUMN old TO new` | ID-based tracking handles this |
| **Reorder columns** | `ALTER TABLE t ALTER COLUMN col AFTER other` | Display order change only |
| **Widen type** | `ALTER TABLE t ALTER COLUMN col TYPE newtype` | intâ†’long, floatâ†’double |
| **Make nullable** | `ALTER TABLE t ALTER COLUMN col DROP NOT NULL` | Remove constraint |

### What You CAN'T Do Without Rewrite

- Narrow types (long â†’ int)
- Change between incompatible types (string â†’ int)
- Add NOT NULL to existing column with NULLs

---

## Catalogs: The Entry Point

### What is a Catalog?

A catalog is like a **phone book** for tablesâ€”it maps table names to their metadata locations.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CATALOG                              â”‚
â”‚                                                             â”‚
â”‚  "catalog.database.table_name"                              â”‚
â”‚            â†“                                                â”‚
â”‚  "s3://bucket/warehouse/database/table/metadata/v5.json"   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Catalog Options

| Catalog | Best For | Notes |
|---------|----------|-------|
| **Unity Catalog** | Databricks users | Full governance, lineage, sharing |
| **Hive Metastore** | Existing Hive users | Widely supported, legacy |
| **AWS Glue** | AWS ecosystem | Native AWS integration |
| **REST Catalog** | Multi-cloud, Tabular | HTTP-based, vendor-neutral |
| **Nessie** | Git-like versioning | Branch/merge for data |
| **JDBC Catalog** | Custom setups | Store in any database |

### Why Catalog Choice Matters

```
Scenario: Multi-Engine Access

Engine A (Databricks)              Engine B (Trino)
        â”‚                                  â”‚
        â”‚  "SELECT * FROM products"        â”‚  "SELECT * FROM products"
        â”‚                                  â”‚
        â–¼                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SHARED CATALOG                          â”‚
â”‚                    (e.g., AWS Glue)                        â”‚
â”‚                                                           â”‚
â”‚    products â†’ s3://bucket/warehouse/products/metadata/    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    Same data files!
                    
âœ… Both engines see the same data
âœ… Changes from one are visible to other
âœ… No data duplication
```

**If catalogs don't match:**
```
Engine A: Uses Catalog X â†’ metadata location A
Engine B: Uses Catalog Y â†’ metadata location B

âŒ Engines see different (or stale) data
âŒ Writes may conflict or be lost
âŒ Multi-engine story falls apart
```

---

## Key Takeaways

### Remember These Points

1. **Metadata is everything** â€” Iceberg's power comes from its layered metadata structure

2. **Snapshots are immutable** â€” Every change creates a new snapshot; old ones remain queryable

3. **Partitions are hidden** â€” Write normal queries; Iceberg handles partition pruning

4. **Schema changes are cheap** â€” Add, drop, rename columns without rewriting data

5. **Catalogs enable sharing** â€” Same catalog = same view of data across engines

### Mental Model

Think of an Iceberg table like a **Git repository for data**:

| Git Concept | Iceberg Equivalent |
|-------------|-------------------|
| Repository | Table |
| Commit | Snapshot |
| Commit history | Snapshot history |
| HEAD pointer | Current snapshot ID |
| Checkout old commit | Time travel query |
| .git folder | Metadata files |
| Working files | Data files |

---

## Next Steps

Now that you understand the concepts, proceed to:

1. **[02-databricks-setup.md](02-databricks-setup.md)** â€” Set up your Databricks environment
2. **[03-phase1-table-creation.md](03-phase1-table-creation.md)** â€” Create your first Iceberg table

---

## Further Reading

- [Apache Iceberg Specification](https://iceberg.apache.org/spec/) â€” The definitive technical reference
- [Iceberg Table Format Paper](https://iceberg.apache.org/papers/) â€” Academic background
- [Databricks Iceberg Documentation](https://docs.databricks.com/en/delta/iceberg.html) â€” Platform-specific guidance
